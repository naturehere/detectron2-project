{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'detectron2''...\n",
      "fatal: protocol ''https' is not supported\n",
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: torch in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: json5 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->datasets) (2025.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PyTorch ÏÑ§Ïπò (CUDA 11.8 Í∏∞Ï§Ä, ÌïÑÏöî Ïãú Í≥µÏãù ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Î≤ÑÏ†Ñ ÌôïÏù∏)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Detectron2 ÏÑ§Ïπò (Colab ÌôòÍ≤Ω)\n",
    "!pip install torch torchvision\n",
    "# !pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "# OpenCV Î∞è Í∏∞ÌÉÄ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
    "!pip install opencv-python numpy json5 tqdm matplotlib datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fvcore \n",
    "pip install cloudpickle\n",
    "pip install omegaconf \n",
    "pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ COCO Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ÏõêÎ≥∏ JSON Ìè¥Îçî Î∞è Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî Í≤ΩÎ°ú\n",
    "json_dir = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\json\"\n",
    "image_dir = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\images\"\n",
    "\n",
    "# COCO JSON Ï†ÄÏû• Í≤ΩÎ°ú\n",
    "coco_output_path = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\"\n",
    "\n",
    "# COCO JSON Íµ¨Ï°∞ Ï¥àÍ∏∞Ìôî\n",
    "coco_format = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "# Ïπ¥ÌÖåÍ≥†Î¶¨ Îß§Ìïë\n",
    "category_mapping = {}\n",
    "category_id = 1\n",
    "annotation_id = 1\n",
    "image_id = 1\n",
    "\n",
    "# JSON ÌååÏùº Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "json_files = [f for f in os.listdir(json_dir) if f.endswith(\".json\")]\n",
    "\n",
    "for json_file in tqdm(json_files, desc=\"Processing JSON Files\"):\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    for pdf_name, pdf_data in dataset.items():\n",
    "        for element in pdf_data[\"elements\"]:\n",
    "            page_num = element[\"page\"]\n",
    "            img_filename = f\"{pdf_name.replace('.pdf', '')}_page_{page_num}.jpg\"\n",
    "\n",
    "            # Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥ Ï∂îÍ∞Ä\n",
    "            if not any(img[\"file_name\"] == img_filename for img in coco_format[\"images\"]):\n",
    "                coco_format[\"images\"].append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": img_filename,\n",
    "                    \"width\": 2480,\n",
    "                    \"height\": 3508\n",
    "                })\n",
    "\n",
    "            # Ïπ¥ÌÖåÍ≥†Î¶¨ Ï∂îÍ∞Ä\n",
    "            label = element[\"category\"]\n",
    "            if label not in category_mapping:\n",
    "                category_mapping[label] = category_id\n",
    "                coco_format[\"categories\"].append({\"id\": category_id, \"name\": label})\n",
    "                category_id += 1\n",
    "\n",
    "            # Ï¢åÌëú Î≥ÄÌôò (Bounding Box Î≥ÄÌôò)\n",
    "            x_min = min(coord[\"x\"] for coord in element[\"coordinates\"]) * 2480\n",
    "            y_min = min(coord[\"y\"] for coord in element[\"coordinates\"]) * 3508\n",
    "            x_max = max(coord[\"x\"] for coord in element[\"coordinates\"]) * 2480\n",
    "            y_max = max(coord[\"y\"] for coord in element[\"coordinates\"]) * 3508\n",
    "\n",
    "            bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
    "\n",
    "            # ‚úÖ `segmentation` ÌïÑÎìú Ï∂îÍ∞Ä (Í∞ÑÎã®Ìïú Îã§Í∞ÅÌòï ÌòïÌÉúÎ°ú Î≥ÄÌôò)\n",
    "            segmentation = [[\n",
    "                x_min, y_min, x_max, y_min, x_max, y_max, x_min, y_max\n",
    "            ]]\n",
    "\n",
    "            # Ïñ¥ÎÖ∏ÌÖåÏù¥ÏÖò Ï∂îÍ∞Ä\n",
    "            coco_format[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": category_mapping[label],\n",
    "                \"bbox\": bbox,\n",
    "                \"area\": bbox[2] * bbox[3],\n",
    "                \"segmentation\": segmentation,  # ‚úÖ Ï∂îÍ∞ÄÎê®\n",
    "                \"iscrowd\": 0,\n",
    "                \"text\": element[\"content\"][\"text\"]\n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "        image_id += 1\n",
    "\n",
    "# COCO JSON Ï†ÄÏû•\n",
    "with open(coco_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(coco_format, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ COCO Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÏôÑÎ£å: {coco_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PDFs to Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:03<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF -> Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò ÏôÑÎ£å!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PDF Î∞è Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
    "pdf_dir = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\pdfs\"\n",
    "image_output_dir = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\images\"\n",
    "\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "# PDF ÌååÏùº Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "\n",
    "# PDFÎ•º Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôò\n",
    "for pdf_file in tqdm(pdf_files, desc=\"Converting PDFs to Images\"):\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    images = convert_from_path(pdf_path, dpi=300)  # PDFÎ•º Í≥†Ìï¥ÏÉÅÎèÑ Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôò\n",
    "\n",
    "    # Î≥ÄÌôòÎêú Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•\n",
    "    for i, img in enumerate(images):\n",
    "        img_filename = f\"{pdf_file.replace('.pdf', '')}_page_{i+1}.jpg\"\n",
    "        img_path = os.path.join(image_output_dir, img_filename)\n",
    "        img.save(img_path, \"JPEG\")\n",
    "\n",
    "print(\"PDF -> Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 2. Detectron2ÏóêÏÑú Custom COCO Dataset Îì±Î°ù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/12 06:54:18 d2.data.datasets.coco]: \u001b[0mLoaded 200 images in COCO format from C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\n",
      "Detectron2 Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Detectron2 Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù\n",
    "register_coco_instances(\"custom_doclaynet\", {}, coco_output_path, image_dir)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌôïÏù∏\n",
    "dataset_metadata = MetadataCatalog.get(\"custom_doclaynet\")\n",
    "dataset_dicts = DatasetCatalog.get(\"custom_doclaynet\")\n",
    "\n",
    "print(\"Detectron2 Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù: ['table', 'paragraph', 'heading1', 'header', 'list', 'figure', 'caption', 'chart', 'footer', 'footnote', 'equation', 'index']\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "# COCO Îç∞Ïù¥ÌÑ∞ÏÖã Îì±Î°ù ÌõÑ, thing_classesÎ•º ÏßÅÏ†ë Ï∂îÍ∞Ä\n",
    "metadata = MetadataCatalog.get(\"custom_doclaynet\")\n",
    "\n",
    "# COCO JSONÏóêÏÑú Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "import json\n",
    "\n",
    "coco_json_path = (\n",
    "    r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\"\n",
    ")\n",
    "with open(coco_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# COCO JSONÏóêÏÑú Ïπ¥ÌÖåÍ≥†Î¶¨ Ï∂îÏ∂úÌïòÏó¨ thing_classes ÏÑ§Ï†ï\n",
    "categories = [cat[\"name\"] for cat in coco_data[\"categories\"]]\n",
    "metadata.thing_classes = categories  # ‚úÖ ÏßÅÏ†ë ÏÑ§Ï†ï\n",
    "\n",
    "print(\"Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù:\", metadata.thing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ COCO JSON ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å! Ïù¥Ï†ú Detectron2ÏóêÏÑú Ïã§ÌñâÌï¥Î≥¥ÏÑ∏Ïöî.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ Î∞è COCO JSON ÌååÏùº Í≤ΩÎ°ú\n",
    "image_dir = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\images\"\n",
    "coco_json_path = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\"\n",
    "\n",
    "# COCO JSON ÌååÏùº Î°úÎìú\n",
    "with open(coco_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÌôïÏù∏ Î∞è COCO JSON ÏàòÏ†ï\n",
    "for img in coco_data[\"images\"]:\n",
    "    img_path = os.path.join(image_dir, img[\"file_name\"])\n",
    "\n",
    "    if os.path.exists(img_path):\n",
    "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è ÌÅ¨Í∏∞ ÌôïÏù∏\n",
    "        image = cv2.imread(img_path)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # COCO JSON ÏóÖÎç∞Ïù¥Ìä∏\n",
    "        img[\"width\"] = width\n",
    "        img[\"height\"] = height\n",
    "\n",
    "# ÏàòÏ†ïÎêú COCO JSON Ï†ÄÏû•\n",
    "with open(coco_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(coco_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ COCO JSON ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å! Ïù¥Ï†ú Detectron2ÏóêÏÑú Ïã§ÌñâÌï¥Î≥¥ÏÑ∏Ïöî.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/12 06:55:49 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=13, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=48, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/12 06:55:49 d2.data.datasets.coco]: \u001b[0mLoaded 200 images in COCO format from C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\coco\\coco_annotations.json\n",
      "\u001b[32m[02/12 06:55:49 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 200 images left.\n",
      "\u001b[32m[02/12 06:55:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/12 06:55:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/12 06:55:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/12 06:55:49 d2.data.common]: \u001b[0mSerializing 200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/12 06:55:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/12 06:55:49 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/12 06:55:49 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[02/12 06:55:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (13, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (48, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (48,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (12, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/12 06:55:50 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/12 06:55:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9  total_loss: 7.325  loss_cls: 2.508  loss_box_reg: 0.1683  loss_mask: 0.6894  loss_rpn_cls: 3.279  loss_rpn_loc: 0.588    time: 0.3318  last_time: 0.3730  data_time: 0.4346  last_data_time: 0.0014   lr: 0.00022503  max_mem: 4671M\n",
      "\u001b[32m[02/12 06:55:58 d2.engine.hooks]: \u001b[0mOverall training speed: 8 iterations in 0:00:02 (0.3318 s / it)\n",
      "\u001b[32m[02/12 06:55:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:03 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "# Mask R-CNN ÌïôÏäµ ÏÑ§Ï†ï\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "cfg.DATASETS.TRAIN = (\"custom_doclaynet\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    ")  # ÏÇ¨Ï†ÑÌïôÏäµ Î™®Îç∏ ÏÇ¨Ïö©\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 10  # ÌïôÏäµ Î∞òÎ≥µ ÌöüÏàò\n",
    "cfg.MODEL.MASK_ON = True\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(dataset_metadata.thing_classes)\n",
    "\n",
    "# ÌïôÏäµ Ïã§Ìñâ\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î™®Îç∏Ïù¥ Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: C:\\Users\\nature\\Documents\\detectron2\\trained_model\\mask_rcnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "output_dir = cfg.OUTPUT_DIR\n",
    "model_final_path = os.path.join(output_dir, \"model_final.pth\")  # ÏµúÏ¢Ö Î™®Îç∏ ÌååÏùº\n",
    "\n",
    "# Î™®Îç∏Ïù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ ÌõÑ Î∞±ÏóÖ\n",
    "if os.path.exists(model_final_path):\n",
    "    save_path = r\"C:\\Users\\nature\\Documents\\detectron2\\trained_model\\mask_rcnn_model.pth\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    shutil.copy(model_final_path, save_path)\n",
    "    print(f\"‚úÖ Î™®Îç∏Ïù¥ Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {save_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÌïôÏäµÏù¥ ÏôÑÎ£åÎêòÏóàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU ÏÇ¨Ïö© Í∞ÄÎä•: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è GPUÍ∞Ä ÎπÑÌôúÏÑ±ÌôîÎê®! CPUÏóêÏÑú Ïã§Ìñâ Ï§ë.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Detectron2 ÏÑ§Ï†ïÏóêÏÑú GPU ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Í∞ïÏ†ú ÏÑ§Ï†ï\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mDEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚úÖ GPU ÏÇ¨Ïö© Í∞ÄÎä•:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPUÍ∞Ä ÎπÑÌôúÏÑ±ÌôîÎê®! CPUÏóêÏÑú Ïã§Ìñâ Ï§ë.\")\n",
    "\n",
    "# Detectron2 ÏÑ§Ï†ïÏóêÏÑú GPU ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Í∞ïÏ†ú ÏÑ§Ï†ï\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/12 07:03:18 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from C:\\Users\\nature\\Documents\\detectron2\\trained_model\\mask_rcnn_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (13, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (13,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (48, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (48,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (80, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "c:\\Users\\nature\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3638.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "save_path =r\"C:\\Users\\nature\\Documents\\detectron2\\trained_model\\mask_rcnn_model.pth\"\n",
    "# Î™®Îç∏ Î°úÎìú\n",
    "# Mask R-CNN ÌïôÏäµ ÏÑ§Ï†ï\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "cfg.MODEL.WEIGHTS = save_path  # ÌïôÏäµÎêú Î™®Îç∏ Í∞ÄÏ§ëÏπò Î∂àÎü¨Ïò§Í∏∞\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n",
    "\n",
    "# ÏòàÏ∏°ÏùÑ ÏúÑÌïú Predictor ÏÉùÏÑ±\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ÌÖåÏä§Ìä∏Ìï† Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞\n",
    "test_image_path = r\"C:\\Users\\nature\\Documents\\detectron2\\dp-bench\\dataset\\images\\01030000000037_page_1.jpg\"\n",
    "image = cv2.imread(test_image_path)\n",
    "\n",
    "# ÏòàÏ∏° Ïã§Ìñâ\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Í≤∞Í≥º ÏãúÍ∞ÅÌôî\n",
    "v = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(\"custom_doclaynet\"), scale=1.0)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# ÏòàÏ∏°Îêú Ïù¥ÎØ∏ÏßÄ Ï∂úÎ†•\n",
    "cv2.imshow(\"Predictions\", v.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. ÌïôÏäµÎêú Î™®Îç∏ÏùÑ ÎÇòÏ§ëÏóê Îã§Ïãú Î°úÎìúÌïòÎäî Î∞©Î≤ï\n",
    "Ïù¥Ï†ú Ï†ÄÏû•Îêú Î™®Îç∏ÏùÑ ÎÇòÏ§ëÏóê Îã§Ïãú Î°úÎìúÌïòÏó¨ Ï∂îÍ∞Ä ÌõàÎ†®ÌïòÍ±∞ÎÇò Îã§Î•∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌï¥ ÏòàÏ∏°Ìï† ÏàòÎèÑ ÏûàÏñ¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DefaultPredictor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Í∏∞Ï°¥ Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mWEIGHTS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnature\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdetectron2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrained_model\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmask_rcnn_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m predictor \u001b[38;5;241m=\u001b[39m DefaultPredictor(cfg)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ÏÉàÎ°úÏö¥ Ïù¥ÎØ∏ÏßÄ ÏòàÏ∏°\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# Í∏∞Ï°¥ Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "cfg.MODEL.WEIGHTS = r\"C:\\Users\\nature\\Documents\\detectron2\\trained_model\\mask_rcnn_model.pth\"\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ Ïù¥ÎØ∏ÏßÄ ÏòàÏ∏°\n",
    "new_image_path = r\"C:\\Users\\nature\\Documents\\detectron2\\doclaynet\\images\\01030000000045_page_2.jpg\"\n",
    "image = cv2.imread(new_image_path)\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Í≤∞Í≥º ÌôïÏù∏\n",
    "v = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(\"custom_doclaynet\"), scale=1.0)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "cv2.imshow(\"Predictions\", v.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
